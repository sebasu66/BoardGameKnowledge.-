Stirring the pot (e.g., resetting everyone’s scores to the starting score, or adding a
random amount to everyone’s score) is somewhat like what people tend to think of
as catch-up, and somewhat not: it doesn’t differentially help losers and hurt winners,
but it tends in practice to hurt winners and help losers simply because the winners
are ahead and the losers are behind. Events of this kind tend to be “catch-up events”

Games as Systems

117

in the sense of decreasing the variance in the state vector when they happen (compared to the variance of the vector when they fail to happen). So one can think of
random elements in a game as being in themselves a kind of catch-up feature—if a
game has a lot of randomness, you are probably not as far ahead as the score (or other
first-order state heuristic) might indicate.
Random features in a game often give rise to “press-your-luck” situations: cases
where a player can choose to make the game more random or less. Typically a player
chooses to make things more random when behind, less random when ahead. Hail
Mary passes in football, going for three-point shots in basketball, guessing in Clue, or
pushing for a risky Yahtzee combination are all examples, but perhaps the ultimate
example of a press-your-luck game is Sid Sackson’s boardgame Can’t Stop.
Over-Catch-Up
Sometimes catch-up features are so strong that it is better to be second, or at the very
least it does not hurt to be second. Race games with lots of ways to hurt the leader,
shoot the person in front of you, speed up if you are behind, and so on, can have this
problem. Highly political games tend to be this way, due to the “pile on the leader”
tendency almost all playgroups have. Over-catch-up tends to be frustrating—people
want to pump up their score, or get ahead in the race, and they do not want to be
punished for it. In theory, jockeying for second (or should it be third?) and then
jumping to win at the end can be a reasonable game, but in practice it is not much
fun if it happens all the time. And games of this type tend to have all the play choices
other than those near the very end of the game be irrelevant to the outcome.
A game with this attribute will generally become less fun when players realize it.
Catch-Up in Very Long-Running Games
Catch-up can take certain unusual forms in games that go on for a very long amount
of time—typically one and a half player games (like single-player RPGs) or MMOs.
Long one and a half player games tend to have a great deal of catch-up: if one thinks
of the basic metric of player level compared to stage in the game (for an RPG), then
grinding is a mechanic that lets the player freely “catch up” anytime she wants. The
same applies to an MMO.
The reason very long games require catch-up is that if a game lasts ten hours (say),
then without some form of catch-up, a losing player would be clearly losing for the
last several hours, which is just too long to be in a state of all-but-certain loss. Of
course, if the catch-up features are extremely strong, one gets the problems one often
sees in these genres: choices in the early stages of the game may not matter very much,
or the player may be discouraged on realizing that a painstaking and tedious method
of play is most likely to guarantee victory. One common attempt to solve the problem
of catch-up in very long games is to use dynamic difficulty adjustment. This basically

118

Chapter 4

amounts to catching up the player invisibly whenever she falls behind, and catching
up the AI if the player moves ahead. The problem is that it is rather like your spouse
cheating on you: arguably fine if you know nothing about it, but liable to make you
feel bad if you do find out about it, which eventually you will (at least in the case of
games, given the Internet). Players who are trying to play well want to feel that if they
do play well, they will be rewarded. This feeling is hard to come by if the game tries
to ensure equal outcomes regardless of player skill.
Even for games with a short game length, one can think of the ongoing metagame
as a corresponding game with very long game length. This very long game has some
of the same issues—for example, if a dozen people all learn to play chess together, as
time goes on their skill levels will spread apart. After a number of months, some of
the players may be in a permanently winning or losing state. Those players have (all
but) won or lost the have-the-most-skill metagame, leading to a bad play experience.
Better players in the group teaching weaker ones provides a sort of catch-up feature,
arguably analogous to level grinding (the weaker players are spending more time
improving their skills, the stronger players are spending less).
Targeting and Catch-Up
A catch-up feature may hit various targets: it may hurt the leader specifically, the
player of your choice, the guy in front of you, a random player, everyone but
you, everyone in front of you, and so on (likewise for catch-up features that help a
player, although “help yourself” is by far the most common sort). Depending on
whom the catch-up feature targets, different gameplay effects can occur. We’ll give
just a few examples of problems that can arise, especially if the catch-up feature is
too strong.
Hurting the leader often tends to lead to over-catch-up and a “play for second”
style of game. Each player hurts the leader, nobody else gets hurt, and thus the lead
cycles regularly, but having the lead isn’t necessarily meaningful. There are no choices,
so the only skill increase comes from the disguise of the first-order “who’s ahead”
heuristic, a heuristic that may be so heavily damaged as to be almost useless.
Hurting your choice of player tends to lead to highly political games. As with any
targeting mechanic, carried to an extreme it may result in a chip-taking game.
Hurting someone near you (in whatever sense the game defines “near”: a player
sitting adjacent to you in a boardgame, a car driving near you in a racing game) can
be good in that it is less political, although of course it does represent some diminishing of player choice. However, such a mechanic—say the Green Shell in Mario Kart
(which, being unaimed, typically is used against players who are close)—may not give
large-scale catch-up. Instead, it may cause clumping: groups of players who are close
together keep shooting each other, forming clumps, but one clump can’t affect another
far-off clump (although occasionally a player will break away from one clump and

Games as Systems

119

push ahead or fall behind until pulled into the orbit of another clump). In this sense
Mario Kart is almost exactly like a large bicycle race, with the Green Shell playing the
same role as drafting: something that pulls together nearby vehicles but does not affect
faraway ones. They are a catch-up feature within a given clump, but less so when
viewed from the point of view of the race as a whole.17
Conclusion: Limitations and Effects of Catch-Up
The limitations presented on catch-up are interesting for both player and designer.
The most critical of these is the idea that catch-up relative to a fixed state heuristic is
real even when the situation relative to winning percentage is not. Any time a player
is in a game that he perceives to have a catch-up feature, there is some indication that
his state heuristics may be insufficient and there is a possible gain in strategic understanding to be had by altering them. Similarly the designer needs to take care that
adding a catch-up feature relative to a state heuristic continues to serve the basic
intention of keeping players excited and hopeful without eliminating some core
element of the game. It is probably true that you don’t want to naively add a catch-up
feature to maintain player hope at the expense, for example, of actually wanting to
be in the lead in a race, or gather the most power in a political game. While the simple
state heuristic of the lead being good in a race is arguably more important than
keeping all players involved, there is often a lot of leeway for players maintaining
naive state heuristics depending on the player audience. It is much more likely that
adding a catch-up feature to a race for children or casual players will be seen as a true
catch-up feature relative to the lead heuristic, rather than causing a shift in player
heuristics to devalue the lead in favor of a more complicated formula. Even for a more
hardcore game, features like dynamic difficulty adjustment may cause players to
believe they “caught up” due to good or lucky play when in fact the existence of the
feature meant they were never really behind. This situation can break down in a game
meant to be highly replayable as players refine their state heuristics. Few players are
interested in a game where they see they always have a 50 percent, or even 95 percent,
chance of winning no matter what they do.
True catch-up in the sense of limiting state vector variance has an important place
as well. Very often this will achieve the goal of continuing player involvement while
maintaining clean first-order heuristics. The difficulty here lies in the potential to
disenfranchise competitive players who may feel slighted they can only be a limited
amount better than a truly bad opponent. Again the audience is the key. A feature
that limits a player’s downside to 1 percent of the leader’s chance to win may not go
17. This whole clumping phenomenon only arises if the outcome of the catch-up affects future
targeting, as in a race game with missiles. If the two are unlinked, as in a card game where you
can only affect players sitting next to you, the clumping won’t happen.

120

Chapter 4

far enough to keep many people interested in the game. Conversely, a feature that
sets that limit at 40 percent may scare away more competitive players.
Catch-up features that either end games or make them fairer can work especially
well in achieving the basic goals for player hope in a long game. They may have the
tendency, however, to create a lack of control over the length of the game, since by
their nature they achieve their leveling by ending some games early. Still, it is encouraging for many to know that there are no bounds on how good they can get at the
game while at the same time worse players will never have to be in a game they feel
they can’t win for long.
Exercise 4.9:
Exercise 4.10:

Give some examples of pressing your luck in baseball and hockey.
Give some examples of pressing your luck in a chess tournament.

Exercise 4.11: What types of audiences would be more interested in games with
catch-up features?
Exercise 4.12: Do games with catch-up features tend to have poor or good state
heuristics? Why?
Exercise 4.13: What are the risks of dynamic difficulty adjustment? Do all the risks
go away if no players know that the difficulty is being adjusted?
Exercise 4.14: For a game to have a “true” catch-up feature what needs to happen?
How might this be beneficial for the player audience? (Hint: Think about the elimination qualities inherent in such a game.)
4.3

Characteristic: Complexity Tree Growth and Game Arc

Game Complexity Trees
One can think of a game as a series of choices.18 In fact, the game designer Sid Meier
famously defined a game as “a series of interesting choices.”19 There are certainly
games with no interesting choices, and in fact examples of games without any choices,
but these tend to be limited to the sphere of gambling. For logical completeness, one
would typically consider all possible choices at any given node (decision point). But
from the point of view of human players, what matters is the number of meaningful
choices. “Meaningful” is of course an inherently agential concept: for the exact same
game state, a beginning player might be choosing at random (no meaningful choices),
an intermediate player might feel pressure to examine a great many choices, and an
18. This point of view is quite explicit in the Nash/Von Neumann game theory’s extensive form,
the definition of game in combinatorial game theory, or the game state trees one searches
through in a computer chess program.
19. Rollings and Morris, Game Architecture and Design, 38.

Games as Systems

121

Figure 4.8
©iStockphoto.com/Baris Simsek

expert might need to examine only a few. Imagine, for example, the number of meaningful choices for players of various skill levels at tic-tac-toe or chess.
Exercise 4.15: How many meaningful choices are there for a beginner at tic-tac-toe?
For an expert? What about a beginner at chess? An expert?
Exercise 4.16: Pick two different games and give a reasonable estimate of how many
choices there are at any point. Do this for both beginner and expert players.
If the number of choices is too low, you hardly have a game at all (Conway’s Life,
or tic-tac-toe or Nim between expert players) or you have a boring one from a strategic
point of view. If the count is too high, you may have a game that is not fun for most
people (go, or an RTS).20
We speak of the game tree as being sparse if there are relatively few choices, and
bushy if there are relatively many. Of course these terms are not absolute, but relative
(say to the number of choices likely to be enjoyed by a particular audience, or compared to other games in the same genre, or compared to some particular other game).
Often we compare the sparseness or bushiness of the game tree at one point in the
play of the game, say the opening, with another point, say the endgame.
Bushiness and sparseness are largely systemic—how many legal actions are there at
a certain point in the game tree? But they are also somewhat agential, because players
20. Of course, these games are fun for those who choose to play them. But that’s a self-selected
audience. The people who find the complexity tree daunting have chosen not to play.

122

Chapter 4

will not necessarily consider all possible choices, but will prune the game tree by
eliminating certain choices from consideration. Pruning can come from eliminating
duplicate moves (i.e., recognizing symmetries) or from quickly recognizing some
moves as bad ones. Pruning can also come from the recognition that some choices
are effectively though not exactly the same—for instance, the exact spot to stand on
a large playfield.
Games that are very sparse or very bushy can be unsatisfying to players. Too sparse,
and players may not feel they have any interesting choices to make—in the extreme
case, where a player always sees a single correct move (as in Nim or tic-tac-toe, say),
one might hardly feel there is a game there at all. Too bushy, and the player may feel
overwhelmed by all the choices and may feel they are left making moves essentially
at random (as happens to beginners in go, or in building certain complex RPG
characters21).
The Game Arc
The game arc is how the bushiness of the tree fluctuates throughout the course
of the game. Commonly the tree will start out sparse, get bushier, and then become
sparse again. This is basically a good thing—it provides the game with good pacing,
and a kind of narrative arc. A typical example would be Monopoly: initially one simply
rolls the dice and makes relatively few decisions (it’s often right just to buy whatever
one can at the start, and houses, hotels, and mortgaging properties are not relevant
in the early game). In the midgame one is deciding on trades, deciding how to invest
in one’s properties, and in general making most of the decisions one makes in the
game. Toward the end things typically settle down again, and one rolls to see who
lands on whose developed properties, along perhaps with continuing to develop
the properties one has decided to focus on. An extreme example would be the card
game Oh Hell, where the expanding and contracting of the game tree is built in
directly, as the hand size (and thus the bushiness of the game tree) changes from round
to round.
One can use diagrams showing the relative number of choices available over the
course of the game as a visual aid to help one understand the game arc. So, for
example, a classic game arc like that of Monopoly, where one starts out with a modest
number of choices, those choices increase, and then finally the choices decrease until
the game ends, would look something like the arc shown in figure 4.9.
Note the rough resemblance to pictures of a narrative arc, with an opening, a
climax, and a denouement. Many, perhaps most, boardgames fall into this pattern.
An RTS can as well, with basic opening build patterns, a complex middle game, and
21. In the case of building RPG characters, one often gets around the feeling of being overwhelmed by following flavor rather than trying to build a powerful character.

123

Bushiness

Games as Systems

Time
Figure 4.9
Classic game arc

relatively fewer choices at the end (perhaps because a max tech level has been reached,
or perhaps the definitive battles have been fought and a mopping-up phase has been
reached).
Even a crossword puzzle might fall into this pattern, with some easy clues answered
early on, then a number of tough clues that don’t cross many other completed answers
needing to be tackled, with the last few clues coming fairly quickly as the final portions of the board are filled out. Similar remarks can be made for card solitaire.
Sometimes a particular game, say of chess, may end suddenly, before the bushiness
decreases. In this case the overall game arc rises as the bushiness increases, and then
suddenly terminates, with no “calm” phase at the end (figure 4.10).
Beginners may experience the game arc somewhat differently. To them, the opening
phases may seem quite confusing—they haven’t learned the standard opening patterns, and so may need to think as hard about the opening as about the middle game,
leading to an arc somewhat like the one in figure 4.11.
One might think of the arc in figure 4.11 as representing a beginner’s chess game,
say. There are slightly fewer possibilities in principle for the opening moves (certain
pieces simply cannot be moved because they are blocked). Still, there are many moves
to consider—for instance, opening rook pawn moves forward two—that an expert can
simply ignore. If one thinks of go, the situation for the beginner is even worse. Even
the theoretical number of opening moves is larger, and the end does not collapse
much either—in fact, when the game is over is not terribly clear, giving rise perhaps
to a diagram as in figure 4.12.

Chapter 4

Bushiness

124

Time

Bushiness

Figure 4.10
A game ending suddenly

Time
Figure 4.11
Game arc—a beginner’s view

125

Bushiness

Games as Systems

?

Time
Figure 4.12
The confusion of the beginning go player

Games in which one places a large army on the field that is then gradually destroyed
(Risk, Warhammer, Myth) often start at maximal complexity and gradually decrease
(figure 4.13).
Some minis games or wargames have rules for reinforcements, which is a way of
getting closer to the classic game arc: more choices for later on, with a somewhat
simpler starting position.
Sports often have a more or less steady game arc. Basketball is not noticeably more
or less complex in the first quarter than in the third (perhaps slightly more right at
the end due to management of the clock) (figure 4.14).
Any game with very short atoms will also tend to have a flat arc like the sports
one. That’s because there’s not much room for an arc inside such a short atom, and
each atom being the same means the overall game arc is flat. Another example of this
flatness of arc can be seen in a tournament (thought of as a game in and of itself):
what a player is doing in the first hour of the tournament is not that different from
what she’s doing in the fifth hour.22 Flatness of arc might be one of the few disadvantages to the otherwise strong game feature of small atoms.
For a paper RPG or an MMO, one has to decide what time period one is looking
at, since the game length is not well defined. Looking at, say, an MMO over the lifetime of a single character, one might say the game arc gradually increases in bushiness
22. Of course, zoomed in the arc may be more complex: it will be the arc of whatever game the
tournament is for (chess, say). But we are speaking here of the large-scale view.

Chapter 4

Bushiness

126

Time

Bushiness

Figure 4.13
Complexity progression in a miniatures battle

Time
Figure 4.14
Sports—roughly constant complexity

127

Bushiness

Games as Systems

Raid leader

Average raid participant

Time
Figure 4.15
MMO—lifetime of one character

(higher-level characters have more options and more difficult challenges) until raiding
starts. In most cases, raiding involves fewer real choices for an individual character,
and indeed the game arc can sometimes get very sparse. The raid leader, however (who
is managing the raid as a whole) is typically engaging in a very complex task. His
game arc might show an increase in bushiness.
Thinking of a single MMO raid as one event, it often follows something like the
classic arc: not too many decisions early on (gather, buff everyone), some choices
further on culminating in a boss fight, after which things are quickly over.
The one-session measure coming from a raid is probably the more important one:
that’s where the narrative-like satisfaction of increasing tension followed by a denouement is at its best.
As mentioned above, some games, like miniatures games and chess, violate the
usual game arc pattern in that they start with a great many pieces on the board and
then gradually shrink as those pieces are destroyed—in other words, their game tree
appears to start maximally bushy and then decrease. Sometimes, however, the early
phases of the game have fewer choices than it might appear: in a minis game, the
pieces start far apart, and the early moves may consist largely of closing the distance,
which is relatively simpler than the midgame. (Although this is true for average
minis players, for very expert players the early maneuvers are extremely complex and
telling, so the game arc pattern of maximal and decreasing bushiness is probably
closer to the truth.) In chess, the mobility of pieces is restricted early on, and opening

Chapter 4

Bushiness

128

Boss

Time
Figure 4.16
MMO—a single raid

patterns are available to tell you what to do, thereby narrowing the meaningful
choices.23
Many, perhaps most, games are like chess in that the opening moves become at
least partially standardized over time. For example, think of the standardized opening
build patterns in an RTS. These openings have the effect of pruning the game tree
during the early game for nonbeginners, but beginners are often more at sea in the
early game. Once again this points out the value of good zero-level heuristics, for
without them beginners will have a worse game arc than more experienced players.
Some games, like RTS games and trading card games, have a very explicit early arc
built in: many game options are simply unavailable early on and must be slowly
enabled. Games of this sort may have the later arc extremely bushy, and sudden
endings are possible: a Magic or a Warcraft III game may end suddenly, with the game
tree still uncollapsed.
One large and important category of games that do not follow the standard game
arc well is sports (and computer games based on the sports model, like Mario Kart or
Street Fighter). Although there is sometimes a collapse at the very end, due to time
23. Go appears different at first, since there are more and more pieces rather than fewer and
fewer. But since those pieces don’t move, the options are really the empty spaces on the board,
and the end result is somewhat like chess: opening theory to guide players in the beginning, and
collapse toward the end as fewer options are available. However, at the very top levels of play
openings in go are perhaps harder than they are in chess, so go can be quite bushy for expert
players—and for beginners with no opening ideas to guide them.

Games as Systems

129

running out or to the outcome being inevitable, by and large the sorts of decisions
players make at the beginning of a soccer game, auto race, or tennis match are similar
to the ones they make during the middle or toward the end.
Exercise 4.17: Think about the complexity tree for Nim. What does it look like for a
beginner? For an expert? For an intermediate player?
Exercise 4.18: Draw some parallels between the “classic” game complexity arc and
the standard three-act narrative structure common in plays and films.
Exercise 4.19: What drawbacks for the player might a game with many options have?
Exercise 4.20: Give an example of a game where the number of meaningful options
increases with player skill.
Exercise 4.21: Construct an example where adding an option to the game decreases
the number of meaningful options.
4.4

Characteristic: Game Balance and Strategic Collapse

Often players and designers worry about game balance or criticize a game for being
unbalanced. Lack of balance can be thought of as a problem with the complexity tree:
the bushiness of the tree is much less than intended because a small number of strategies are much better than the others. Phrased another way, the game seems to be
offering a large number of interesting choices, but on closer examination it turns out
only a few of them are viable, so the fun of the game is not realized. Players just use
those few choices again and again. The heuristics of the game have been reduced from
the potentially rich and satisfying collection that might have existed to a very simple
heuristic: play only with the much better strategies.
Phrasing the problem in terms of complexity trees lets us make some additional
observations we might otherwise have missed. First of all, saying the tree’s bushiness
is less than “intended” raises the question of intended by whom. The answer is some
mixture of designer intent and genre convention (player expectation). For example,
in an RTS players expect that almost every unit has some use. If one can always achieve
victory by building nothing but one particular unit, that game is considered unbalanced. In fact, players and designers often feel so strongly about this problem that
they will refer to the game (or the unit) as “broken,” meaning that once you discover
the strategy of just building that unit, the game is no longer working as intended, to
the point where it is analogous to a broken machine. If a unit in an RTS is so bad that
one never builds it, that also fails to meet players’ expectations (although the game
as a whole is rarely declared “broken” merely because of that—a single bad unit does
not cause the decision tree to collapse the way a single very good unit can, so the rest
of the game remains reasonable). Most RTS games have a modest number of units,

130

Chapter 4

Figure 4.17

and the conventions of the genre are such that players expect, or at least hope, that
all will be useful, at least in some situations. Designers generally try to adhere to this
expectation, so the “intention” is indeed some mix of player expectation and designer
intent.
In an MMO, on the other hand, there are an enormous number of items, and the
genre convention is that most of them are not that good compared to the best items.
Because this is expected, players and designers do not usually consider it a problem
that many items are so bad that one would never want to use them. However, items
that are so good that they are the only thing one would consider using (in that particular item slot) are sometimes considered “broken.” The ideal, perhaps, is that of all
the items for a given slot, there will be a handful that are reasonable to decide among,
and a large number that are not worth considering. The end result is that the question
“What item do I put in this slot?” has a reasonable bushiness, at least for those in the
know. (Those not in the know are probably not choosing from the entire set of possible items, but just from some smaller subset available at their level of play, so the

Games as Systems

131

bushiness of the decision node is reasonable for them as well.24) Again, what is
“intended” is a mix of player expectation and designer intent.
In other words, the amount of balance expected in RTS units and in MMO items
are examples of standards. Of course other genres have widely differing standards of
balance—for example, those in Magic or other trading card games.
Saying imbalance is a problem with the decision tree’s bushiness also reminds us
that imbalance must be relative to some set of heuristics, because the tree’s bushiness
for a given player is dependent on the heuristics that player is using. Thus balance is
not only an expert phenomenon. It is perfectly possible for an imbalance to occur at
the level of beginner heuristics: some strategy may be executable by a beginner, and
all but unbeatable by the things a beginner can do in response. One example might
be the strategy of rushing in an RTS where rush defense requires at least an intermediate level of skill. An imbalance at the beginner level is bad—it may cause the beginner
to quit before gaining a higher level of skill—but at least there is some way out, namely
to become a more expert player. Moreover, small advantages of one strategy (or unit,
or item, etc.) over another tend to be more telling at an advanced level, so serious
imbalances are more likely to occur there. All this means designers tend to worry more
about imbalance at the expert level, which is quite natural. But a bit of worrying at
the beginner level is also appropriate.
Options Offered, Options Received
Good game designers have some idea of the choices players might make, and they try
to offer enough choices to make the game fun and interesting.
But because of the risk of imbalance, there is a paradox that offering more options
does not necessarily lead to the player having more options. At least for players in the
know, the real options are the “good” ones, and adding an additional bad one doesn’t
really increase the available options. Adding one that’s much better than the others
is even worse—it destroys all the previous options as viable choices. Think for example
of an MMO where one is faced with a choice of six character classes: add a new class
24. Note that a similar phenomenon occurs when playing Magic in a constructed environment
versus a limited one. In a constructed environment, the entire card pool is available in principle,
so you consider only the top cards, and a great many other cards are not good enough to be
worth considering. In a limited environment, you are choosing from a smaller pool of cards—the
ones that are in front of you at that moment—but more of them will make the cut. The difference is that in an MMO, typically high-skill players play “constructed” and more casual players
play “limited,” whereas in Magic a high-skill player might deliberately choose to play limited,
because it is set up as a specific environment with its own rules. One could imagine doing the
same thing for an MMO, but to our knowledge it has not been done formally yet (it happens
casually all the time, of course, any time an expert decides to level up a new character “just for
fun” without twinking).

132

Chapter 4

that is not as good, and the expert player still has six choices. Add a new class that is
better, and she now has one choice (i.e., no choice at all). Beginners might still have
choices to make, but they will not be so happy when they eventually learn they made
the “wrong” choice. And they surely will learn if the game has multiplayer play,
although a beginner who has made a “bad” choice might never know in a single-player
game (assuming he never goes online for hints or tips and tricks, and he does not
learn too much over the course of the game). But even then the designer is left with
a quandary: Are the other parts of the game (e.g., the monster difficulty) balanced for
the player making the “right” choice (destroying the poor soul who’s chosen unwisely)
or for the player making the “wrong” choice (boring the player who has chosen well)?
Balance problems can occur at the strategic (large-scale) level, like picking a character class or a style of Magic deck. They can also occur at the tactical (small-scale)
level, like picking an item for your character or a card for your deck. And imbalances
don’t have to be item-based: they can also be choices in game actions you take, such
as disc jumping in Tribes25 or rushing in a badly balanced RTS. For another example,
expert players in tournament no-limit poker can find themselves playing against less
skilled players who go all in when they have a good hand and drop out otherwise. If
this strategy works too well, then the rich strategic area of postflop play suffers—and
for that reason there are experts who prefer pot-limit poker, which they would view
as “more balanced.”
Just as adding an extra choice (such as an unbalanced RTS unit or RPG character
class) can actually reduce the real choices in the game, eliminating a choice can sometimes increase the number of real choices. In Magic, a low-level example would be
banning a specific overpowered card; a high-level example would be the color wheel
itself (which restricts the cards you can play with in any given deck, but increases the
number of viable decks overall).
Kinds of Imbalance
A gameplay choice can fail to be balanced in roughly three different ways, in increasing order of severity:
1. It can be too weak. As discussed above, sometimes this is okay, or even desirable
(to keep the decision node at a reasonable size). What’s important are not violating
standards for no reason and having the right number of choices remaining when the
weak ones are discarded.
2. It can be too strong, to the point where it drives out other choices of an equivalent
type, but not all choices in the game. An example might be a flying unit in an RTS
25. In Tribes, you could shoot one of the weapons (the Spinfusor) into the ground, which in
conjunction with the jetpack allowed you to spend a large amount of time in the air, making
you much harder to hit.

Games as Systems

133

that’s better than all the other flying units. If you build a flying unit, you’ll build this
one, but you still have the choice of whether to build a flying unit, and when you
build nonflyers you have choices of which ones to build (assuming they are still balanced with each other). In an MMO, a helmet that’s better than any other helmet (at
the level cap, say) might drive out all your other helmet choices, but you still have
choices for all your other item slots (and choices of character skills, which abilities to
use in combat, and so on). In Magic, there might be some two-mana green creature
card that every green deck will want four copies of, but there are still all the nongreen
decks, and even the green ones have lots of other cards to choose from for the other
slots.
3. It can be so strong that it drives out a huge number of other choices, perhaps to
the point of determining the winner of the game. In a badly balanced RTS, you might
have a single unit that’s so good, your best strategy is to build nothing but that one
unit. In an MMO, the “Helmet of Always Winning” would be so powerful you
wouldn’t care about your other equipment choices—or a spell that did far too much
damage might be the only spell you ever bothered to cast. In Magic, a blue card so
powerful that everyone played blue, and games hung on who drew that particular
card first, and the other cards in the deck all went toward supporting that card, would
turn a game of making choices in deckbuilding into a game with one choice (i.e., no
choices): play the broken blue card.
Games with Explicit Costing Systems
Some games have explicit systems built into them that require a player to pay an
in-game cost in order to use some object in the game (by “objects” we mean a collection from which a player chooses—cards in a deck, spells an MMO character can cast,
units in an RTS, equipable items in an RPG).26
Such games tend to have two properties: there are many objects in the game, and
players choose from among those objects as part of creating their strategy—they create
a deck, or a character, or an army. Typical examples are trading card games, plastic or
metal miniatures games, RTS games, and MMOs. Such games are a fairly modern
phenomenon, perhaps because to reach a large enough player base they more or less
require mass production and large amounts of leisure time. The earliest examples are
probably military simulation wargames, which date back only to the eighteenth
century.27
26. For further details, see Gutschera, “Costing and Balancing Game Objects.”
27. One could consider a professional sports team as an example also, although the issues are
somewhat different in that the costs are not set by the game designer, and relatively few people
get to play the game at the team-building (object choice) level. In any case, the time period is
not that different.

134

Chapter 4

Games such as these, with their large number of objects and player freedom to
choose among them, present special balance problems. In chess, the queen is better
than the other pieces, but each player only has one and is not allowed to bring more.
If a player is allowed to bring as many queens as he wants, something must offset the
queen’s power. That something is the explicit costing system.
So the first advantage of the explicit system is that it allows units to be of different
power levels without the game being unbalanced—the game simply needs to charge
more for the more powerful objects. This cost differential is what allows a game like
Starcraft to have both battlecruisers and marines, even though the former are much
more powerful than the latter on a unit-by-unit basis.
A second advantage of an explicit costing system is as a balance aid to the designer.
By separating cost from effect, the designer can choose the effect she wants based on
criteria other than balance, and then tweak the cost separately until the balance is
right. This is much easier than trying to tweak a whole number of different effects on
an object until that object is perfectly in balance with other comparable objects.
On the downside, the explicit costing system typically adds to the complication of
the game.28 And it never works perfectly in a game with a very large number of objects.
Such games always need adjustments if the competitive pressure is large, lest the game
suffer some amount of strategic collapse. There are always cards in Magic that need
banning, and there are always balance fixes needed in a large MMO. A game with
fewer units, like an RTS, can eventually reach a more or less stable state, but even that
takes an enormous amount of time and energy if one desires a level of balance suitable
for competitive play.
Implicit Subgames as Balance Mechanisms
No one needs to worry about strategic collapse in rock-paper-scissors. All three choices
will be constantly viable. Even if one were to construct a version of RPS where Rock
had a 10 percent chance of beating paper, the game would still contain all three
choices as viable options, albeit ideally chosen at different rates than the standard
game. There are many balanced implicit subgames whose existence can help to guarantee a minimum degree of choice for the player. These can be built in somewhat
explicitly (e.g., color A beats color B beats color C beats color A in a trading card game)
or can be included more subtly as a general strategic truism (e.g., ranged units beat
slow armored units, which beat fast melee units, which beat ranged units). By building
in many copies of these uncollapsible games, the designer is able to set maximum
28. The burden of the added complication for the player can be modest if the costing system
makes sense intuitively—charging gold to buy things in a game that is simulating an economy
is natural enough that players will understand it quite quickly. But in a game like Magic, where
the costing system is more abstract, the mental burden is much greater.

Games as Systems

135

levels of strategic collapse. As in political games, which tend also to be inherently
balanced, the art of the designer is in making these subgames not overly obvious or
dominant so there is still much play left in climbing the heuristic tree.
Exercise 4.22: For a general manager in professional sports, what prevents strategic
collapse in terms of team construction (i.e., think of constructing the best possible
team roster as a game in itself—what prevents strategic collapse in this game)?
Exercise 4.23: What are some rules and restrictions added to basketball after 1945
intended to prevent strategic collapse?
Exercise 4.24: What are some drawbacks of eliminating certain cards, miniatures, or
digital objects from a game’s play environment, when done to prevent strategic
collapse?
Exercise 4.25: Does every character class in an RPG need to be played equally to
avoid strategic collapse? In a game with four character classes, what usage data for the
classes played should cause a designer to worry? A game with ten character classes?
With fifty?

5 Indeterminacy

We promised a certain agnosticism as to game definition—what was and wasn’t
“really” a game. But if we had to pick one ingredient that was necessary (although
not sufficient) for something to be a game, uncertainty in outcome would probably
be it.1 Without getting into the mires of definition, it is safe to say that most if not
all games have some uncertainty as to their outcome. But what does that really mean?
Where does that uncertainty come from?
We begin by talking about uncertainty, or randomness, by itself. It is a truism that
some games have more randomness—more luck—than others. Nailing down what
that means is a bit tricky. Classic random elements like cards or dice are relevant, but
they are not the sole determiners of the amount of luck in a game. We try to categorize
some of the others. Classic games often have large amounts of luck, computer games
and sports quite a bit less; we try to examine the effects of luck in a game and to make
the case that luck is not necessarily a bad thing that must be eliminated.
People often speak of luck and skill as being opposing forces. We don’t agree with
this point of view, and we try to untangle what is really going on, and how luck and
skill relate.
Lastly, we look at one particular source of uncertainty in a game’s outcome, namely
hidden information, and tease out the relationship between it and other sources of
randomness.
5.1

Characteristic: Randomness

Some games have a great deal of randomness, and others have much less. If an average
chess player plays a game against Kasparov, the outcome is all but certain; similarly
1. The other candidate would probably be being done “for fun”—that is, not for a serious purpose
but rather for entertainment or enjoyment. There’s lots of unpacking to be done here to pursue
these thoughts properly. See for example Salen and Zimmerman’s Rules of Play, chaps. 7, 22;
Caillois’s Man, Play, and Games, chap. 1; or Huizinga’s Homo Ludens (especially the first two
chapters).

138

Figure 5.1
©iStockphoto.com/Akadiusz Iwanicki

Chapter 5

Indeterminacy

139

for a game of tennis or a game of Starcraft in which an average player goes up against
a pro. But in a game of backgammon or a hand of poker, the outcome is by no means
certain, although the better player certainly has some kind of advantage.
Although everyone has the intuition that some games are more random than
others, putting one’s finger on what that means is difficult. We won’t build a perfect
formal definition, but we will try to clarify the concept of randomness in games. Then
we’ll talk about the different ways randomness can arise in games. Finally, we’ll talk
about some of the effects of having more or less randomness in a game. The relationship between randomness and skill is a large enough topic that we will save it for
section 5.2.2
What Is Randomness?
We define randomness (or “luck”—we use the terms synonymously) in a game as
uncertainty in outcome. In particular, randomness is not the same thing as random
elements such as dice or cards. Random elements tend to increase the amount of
randomness (uncertainty). But games can have other sources of uncertainty—rockpaper-scissors has no overt random elements, but it is highly uncertain. And even
chess has some uncertainty to it, although it has no random elements of any kind
built into its game mechanics.
Luck is also not by any means the opposite of skill. Chess and poker both have a
lot of skill, even though the first has very little luck and the second has a great deal.
Tic-tac-toe and Candyland have very little skill, even though the first has very little
luck (essentially none among decent players) and the second has a great deal. Note
that in some sense, if there is no uncertainty in outcome, there is arguably no game
at all. If you understand how to play a perfect game of tic-tac-toe or Nim, playing
seems more like performing an algorithm than like playing a game. Most games tend
to exist in the space where there is some opportunity to make meaningful decisions,
which means it is possible to play better or worse, but not possible always to play 100
percent correctly.
A few games exist where one makes no decisions at all (one just declares certain
random outcomes as “wins” and others as “losses” and then rolls the dice or pulls the
slot-machine lever to see which outcome one gets), but people almost never play
predetermined games.
Randomness—a Slippery Concept
Uncertainty in game outcome is a slippery concept for several reasons. One is
that uncertainty itself is philosophically difficult. Generally, we think of a die roll as
2. Much of the material in this section and the next first appeared in Garfield’s “Getting Lucky.”

140

Chapter 5

random. But perhaps that is simply a reflection of our ignorance. Perhaps if we knew
more about the exact shape and weight of the die, how it was thrown, the air currents
in the room, and so on, the die’s outcome would be deterministic. This is the viewpoint of classical (prequantum) physics—the deterministic world machine, the clockwork universe of Newton.3 It’s generally held that there exists “true randomness” in
quantum mechanics, but it is not clear that it is relevant for things like die rolls or
other game randomizers.
A fairly practical approach is to think of uncertainty as arising in situations where,
due to ignorance or to some deeper reason, we simply do not know the outcome, but
various rules of probability apply. This approach is the one we will take. In this sense,
chess is very much random: for a given game, the standard Elo rating system (see
section 5.2 on luck and skill for details) in chess gives a probabilistic prediction for
the outcome of the game based on the difference in ratings between the two players.
And for players whose ratings are reasonably close, one cannot predict with any certainty who will win.
Note that taking a probabilistic approach to game randomness means that many
of the usual perspectives of probability are available to us. For example, it is well
known that people tend to see nonexistent patterns in random sequences, and the
same phenomenon occurs in games, where people often see hot or cold streaks that
don’t really exist.4
Chess is one example of a game without overt random elements where luck (as
uncertainty in outcome) arises. For an even more extreme example, recall our toy
game “Guess the Digit,” where each player tries to guess a specific digit of pi (e.g., the
millionth digit). This game is completely deterministic in principle, but in actual
practice it’s a coin flip. So as actually played, the game is completely random, in the
sense that its uncertainty in outcome is maximal (and the outcome follows the simple
50/50 probability distribution). One might imagine that in theory knowing something
about the distribution of pi’s digits could make the game have some skill, and certainly
having a perfect memory or access to a powerful computer would help, but absent
such advantages there’s not much to the game. Although “Guess the Digit” seems
highly artificial (and admittedly its main value is as a thought experiment), note that
3. For a game analog, consider clock solitaire, where the entire tableau of cards is laid out (face
down) in the form of a clock, and then the game is played in a completely deterministic fashion
to see if the tableau is a winning one or a losing one. We consider the outcome of the game
uncertain, and thus random in our sense, because it is uncertain to the player, even though the
outcome is predetermined once the cards have been laid out.
4. See, for example, Kahneman, Slovic, and Tversky, Judgment under Uncertainty, chap. 3; Gilovich,
Vallone, and Tversky, “The Hot Hand in Basketball”; and Levine, “Do Baseball Players Have Hot
Streaks?”

Indeterminacy

141

in some sense every computer game that uses pseudo-random number generation as
a source of randomness has a game like “Guess the Digit” as a subgame.
In general, “What is randomness?” is a complex question. A great many people
have analyzed it at great length.5 We aren’t planning to go any further into the philosophical points, but the reader should be aware that there are deep waters here.
Aside from philosophical and mathematical issues, another way luck in games is
hard to discern relates to exactly what one says is uncertain. It can’t be just an individual match: the outcome of a game between two evenly matched chess players or
two evenly matched Candyland players (i.e., any two Candyland players) is equally
uncertain (50/50), but we don’t want to say chess and Candyland have the same
amount of luck. A better point of view is that a game has more luck if a beginner can
often beat an expert. Of course, the way we can tell someone is an expert is that she
wins more often, so at this point the interplay between skill and luck starts to matter.
We’ll say more about this subject in the next chapter.
Amount of Luck
The amount of luck in games varies by genre. Gambling games typically have a lot of
luck. Sports typically have very little luck.6 Computer games sometimes have some
luck, but often they have very little—think how unlikely it is for someone who learned
to play Starcraft last week to beat one of the top players, for example. Classic games
have widely varying amounts of luck, and it’s often quite easy to see how much: simply
